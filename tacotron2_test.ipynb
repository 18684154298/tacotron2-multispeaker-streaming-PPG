{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 准备数据 "
      ],
      "metadata": {
        "id": "zCFycZb6Ovdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-1cpCQ2Oncg",
        "outputId": "3f687198-2c80-446e-f7e2-673e1d33bc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tacotron2'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 147 (delta 46), reused 0 (delta 0), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (147/147), 1.74 MiB | 11.08 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Anti-Entrophic/tacotron2-multispeaker-streaming-PPG.git tacotron2\n",
        "!git submodule init\n",
        "!git submodule update"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下载LibriSpeech\n"
      ],
      "metadata": {
        "id": "X7NviSxqPvdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget --no-check-certificate -r https://us.openslr.org/resources/12/train-clean-100.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCZkVnTGPycu",
        "outputId": "42353a82-712c-4298-b948-fd36f78b6b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-02-12 15:30:13--  https://us.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving us.openslr.org (us.openslr.org)... 46.101.158.64\n",
            "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘us.openslr.org/resources/12/train-clean-100.tar.gz’\n",
            "\n",
            "us.openslr.org/reso 100%[===================>]   5.95G  27.3MB/s    in 3m 47s  \n",
            "\n",
            "2023-02-12 15:34:01 (26.8 MB/s) - ‘us.openslr.org/resources/12/train-clean-100.tar.gz’ saved [6387309499/6387309499]\n",
            "\n",
            "FINISHED --2023-02-12 15:34:01--\n",
            "Total wall clock time: 3m 48s\n",
            "Downloaded: 1 files, 5.9G in 3m 47s (26.8 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 解压LibriSpeech\n",
        "%cd /content/us.openslr.org/resources/12\n",
        "import tarfile\n",
        "filename = \"train-clean-100.tar.gz\"\n",
        "tf = tarfile.open(filename)\n",
        "tf.extractall('/content')"
      ],
      "metadata": {
        "id": "eM4wUIXxQBGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安装依赖"
      ],
      "metadata": {
        "id": "lgsfIIQ4QLfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==1.15.2\n",
        "!pip install -q unidecode tensorboardX\n",
        "!pip install librosa==0.8.0\n",
        "!pip install pysoundfile==0.9.0.post1\n",
        "!pip install inflect==5.6.2\n",
        "!pip install janome==0.4.2\n",
        "!pip install resemblyzer"
      ],
      "metadata": {
        "id": "UeJk7LfcQNYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 为了下面能够直接下载预训练模型\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTKmm4AZRCPy",
        "outputId": "35bc7eb4-11c2-4edc-f34a-840f209347da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 创建文件夹 & 下载预训练模型"
      ],
      "metadata": {
        "id": "Tbv-t-lgRPa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.getcwd() != '/content/tacotron2':\n",
        "    os.chdir('/content/tacotron2')\n",
        "# 但是这个预训练模型,之后应该是不能用的.\n",
        "! gdown --id 1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA\n",
        "if not os.path.isdir(\"wavs\"):\n",
        "    os.mkdir('wavs')\n",
        "if not os.path.isdir(\"filelists\"):\n",
        "    os.mkdir('filelists')\n",
        "if not os.path.isdir(\"outdir\"):\n",
        "    os.mkdir(\"outdir\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipPIErbPQuuN",
        "outputId": "f7198386-3e5e-4b0c-c837-358dd1eb6608"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA\n",
            "To: /content/tacotron2/tacotron2_statedict.pt\n",
            "100% 113M/113M [00:00<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 整理数据"
      ],
      "metadata": {
        "id": "G3IkB1frR8NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 需要手动做的事情:"
      ],
      "metadata": {
        "id": "py7u5aTtUS5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 准备训练"
      ],
      "metadata": {
        "id": "BG9FQFVlTcAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 准备日志模块, 输出调试信息"
      ],
      "metadata": {
        "id": "K2piheMITi2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tacotron2\n",
        "if not os.path.isdir(\"log\"):\n",
        "    os.mkdir('log')\n",
        "import logging\n",
        "logging.basicConfig(level=logging.DEBUG #设置日志输出格式\n",
        "                ,filename=\"log/experiment1.log\" #log日志输出的文件位置和文件名\n",
        "                ,format=\"%(asctime)s-%(levelname)s: %(message)s\" #日志输出的格式\n",
        "                  # -8表示占位符，让输出左对齐，输出长度都为8位\n",
        "                ,datefmt=\"%Y-%m-%d %H:%M:%S\" #时间输出的格式\n",
        "                ,force=True\n",
        "                )\n",
        "# 使用logging.debug就可以输出调试信息了，直接print到终端其它输出多了可能不好找\n",
        "logging.debug(\"debug!\")\n",
        "\n",
        "%cd /content/tacotron2/tacotron2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDSbY6dATiNs",
        "outputId": "646bc2b3-b4f9-4400-a4fa-64a1170494c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tacotron2\n",
            "/content/tacotron2/tacotron2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-12T04:22:26.512807Z",
          "iopub.status.busy": "2022-08-12T04:22:26.512405Z",
          "iopub.status.idle": "2022-08-12T04:22:48.851514Z",
          "shell.execute_reply": "2022-08-12T04:22:48.850448Z",
          "shell.execute_reply.started": "2022-08-12T04:22:26.512767Z"
        },
        "trusted": true,
        "id": "VKFIe_5pIZg9"
      },
      "outputs": [],
      "source": [
        "# 训练模型的代码\n",
        "%matplotlib inline\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import math\n",
        "from numpy import finfo\n",
        "\n",
        "import torch\n",
        "from distributed import apply_gradient_allreduce\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import Tacotron2\n",
        "from data_utils import TextMelLoader, TextMelCollate, PPG_MelLoader\n",
        "from loss_function import Tacotron2Loss\n",
        "from logger import Tacotron2Logger\n",
        "from hparams import create_hparams\n",
        " \n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import layers\n",
        "from utils import load_wav_to_torch, load_filepaths_and_text\n",
        "from text import text_to_sequence # 在我导入的时候，是不是会自动调用text文件夹中的__init__.py？\n",
        "from math import e\n",
        "#from tqdm import tqdm # Terminal\n",
        "#from tqdm import tqdm_notebook as tqdm # Legacy Notebook TQDM\n",
        "from tqdm.notebook import tqdm # Modern Notebook TQDM # tqdm可以实现进度条的显示\n",
        "from distutils.dir_util import copy_tree\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def create_mels():\n",
        "    print(\"Generating Mels\")\n",
        "    stft = layers.TacotronSTFT(\n",
        "                hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
        "                hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
        "                hparams.mel_fmax)\n",
        "    def save_mel(filename):\n",
        "        audio, sampling_rate = load_wav_to_torch(filename)\n",
        "        if sampling_rate != stft.sampling_rate:\n",
        "            raise ValueError(\"{} {} SR doesn't match target {} SR\".format(filename, \n",
        "                sampling_rate, stft.sampling_rate))\n",
        "        audio_norm = audio / hparams.max_wav_value\n",
        "        audio_norm = audio_norm.unsqueeze(0)\n",
        "        audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "        melspec = stft.mel_spectrogram(audio_norm)\n",
        "        melspec = torch.squeeze(melspec, 0).cpu().numpy()\n",
        "        np.save(filename.replace('.wav', ''), melspec)\n",
        "\n",
        "    import glob\n",
        "    wavs = glob.glob('wavs/*.wav')\n",
        "    for i in tqdm(wavs):\n",
        "        save_mel(i)\n",
        "\n",
        "\n",
        "def reduce_tensor(tensor, n_gpus):\n",
        "    rt = tensor.clone()\n",
        "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
        "    rt /= n_gpus\n",
        "    return rt\n",
        "\n",
        "\n",
        "def init_distributed(hparams, n_gpus, rank, group_name):\n",
        "    assert torch.cuda.is_available(), \"Distributed mode requires CUDA.\"\n",
        "    print(\"Initializing Distributed\")\n",
        "\n",
        "    # Set cuda device so everything is done on the right GPU.\n",
        "    torch.cuda.set_device(rank % torch.cuda.device_count())\n",
        "\n",
        "    # Initialize distributed communication\n",
        "    dist.init_process_group(\n",
        "        backend=hparams.dist_backend, init_method=hparams.dist_url,\n",
        "        world_size=n_gpus, rank=rank, group_name=group_name)\n",
        "\n",
        "    print(\"Done initializing distributed\")\n",
        "\n",
        "\n",
        "def prepare_dataloaders(hparams):\n",
        "    # Get data, data loaders and collate function ready\n",
        "    \n",
        "    # 在data_utils中定义的类,这个类是继承的torch.utils.data.Dataset\n",
        "    # 它的作用是，读取\"音频，文本\"对，将文本信息转化为sequence，计算音频文件的梅尔谱\n",
        "    trainset = TextMelLoader(hparams.training_files, hparams) \n",
        "    valset = TextMelLoader(hparams.validation_files, hparams)\n",
        "    # 用于整理sequence\n",
        "    collate_fn = TextMelCollate(hparams.n_frames_per_step)\n",
        "\n",
        "    # TODO\n",
        "    trainset = PPGMelLoader(hparams.training_files, hparams)\n",
        "    valset = PPGMelLoader(hparams.validation_files, hparams)\n",
        "    # 我不确定PPG需不需要collate\n",
        "\n",
        "    if hparams.distributed_run:\n",
        "        train_sampler = DistributedSampler(trainset)\n",
        "        shuffle = False\n",
        "    else:\n",
        "        train_sampler = None\n",
        "        shuffle = True\n",
        "\n",
        "    # 调用pytorch的DataLoader\n",
        "    train_loader = DataLoader(trainset, num_workers=1, # 这个参数是指几线程读取数据\n",
        "                shuffle=shuffle, sampler=train_sampler,\n",
        "                batch_size=hparams.batch_size, pin_memory=False, drop_last=True, collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, valset, collate_fn\n",
        "\n",
        "\n",
        "def prepare_directories_and_logger(output_directory, log_directory, rank):\n",
        "    # 准备输出路径 和 输出调试信息的工具\n",
        "    if rank == 0:\n",
        "        logging.debug(\"在prepare_directories_and_logger中，rank=0\")\n",
        "        if not os.path.isdir(output_directory): # 检查是否有输出路径，没有就创建一个。（前面应该创建过了）\n",
        "            logging.debug(\"没有output_directory，创建一个\")\n",
        "            os.makedirs(output_directory)\n",
        "            os.chmod(output_directory, 0o775) # 反正这步就是设置权限，不懂linux。775，第一个7指文件所有者可读可写可执行，第二个7指与文件所有者同属一个用户组的其他用户可读可执行，第三个5指其它用户组可读可执行\n",
        "        logger = Tacotron2Logger(os.path.join(output_directory, log_directory)) # 在 logger.py中定义的类\n",
        "        # 这个类继承了torch.utils.tensorboard中的SummaryWriter类，顾名思义是记录信息的\n",
        "    else:\n",
        "        logging.debug(\"在prepare_directories_and_logger中，rank!=0\")\n",
        "        logger = None\n",
        "    return logger\n",
        "\n",
        "\n",
        "def load_model(hparams):\n",
        "    model = Tacotron2(hparams).cuda()\n",
        "    if hparams.fp16_run:\n",
        "      logging.debug(\"在load_model()中，启用fp16_run\")\n",
        "      model.decoder.attention_layer.score_mask_value = finfo('float16').min\n",
        "\n",
        "    if hparams.distributed_run:\n",
        "      logging.debug(\"在load_model()中，启用distributed_run\")\n",
        "      model = apply_gradient_allreduce(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def warm_start_model(checkpoint_path, model, ignore_layers):\n",
        "    # 这个函数暂时没看，因为还没用上warm_start\n",
        "    assert os.path.isfile(checkpoint_path)\n",
        "    print(\"Warm starting model from checkpoint '{}'\".format(checkpoint_path))\n",
        "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model_dict = checkpoint_dict['state_dict']\n",
        "    if len(ignore_layers) > 0:\n",
        "        model_dict = {k: v for k, v in model_dict.items()\n",
        "                      if k not in ignore_layers}\n",
        "        dummy_dict = model.state_dict()\n",
        "        dummy_dict.update(model_dict)\n",
        "        model_dict = dummy_dict\n",
        "    model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    assert os.path.isfile(checkpoint_path) # 打开对应路径下的模型\n",
        "    print(\"Loading checkpoint '{}'\".format(checkpoint_path)) # 调试信息：Loading checkpoint '/content/drive/MyDrive/colab/outdir/test'\n",
        "\n",
        "    # torch.load()用来加载torch.save()保存的文件\n",
        "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "    # 继承自torch.nn的方法，用于将预训练的参数权重加载到新的模型之中\n",
        "    logging.debug(type(checkpoint_dict['state_dict']))\n",
        "    model.load_state_dict(checkpoint_dict['state_dict']) # 不懂这步checkpoint_dict['state_dict']是什么意思\n",
        "    # 大概是把一些预训练的参数加到model上吧\n",
        "    optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
        "    learning_rate = checkpoint_dict['learning_rate']\n",
        "    iteration = checkpoint_dict['iteration'] # 这步就是返回上次训练到哪个iteration了\n",
        "    # 主要不懂这个checkpoint的保存形式，感觉好像有一些键值对？\n",
        "\n",
        "    print(\"Loaded checkpoint '{}' from iteration {}\" .format( # 调试信息：Loaded checkpoint '/content/drive/MyDrive/colab/outdir/test' from iteration 17\n",
        "        checkpoint_path, iteration))\n",
        "    return model, optimizer, learning_rate, iteration\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, learning_rate, iteration, filepath):\n",
        "    print(\"Saving model and optimizer state at iteration {} to {}\".format(\n",
        "        iteration, filepath))\n",
        "    try:\n",
        "        torch.save({'iteration': iteration,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'learning_rate': learning_rate}, filepath)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"interrupt received while saving, waiting for save to complete.\")\n",
        "        torch.save({'iteration': iteration,'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(),'learning_rate': learning_rate}, filepath)\n",
        "    print(\"Model Saved\")\n",
        "\n",
        "def plot_alignment(alignment, info=None):\n",
        "    %matplotlib inline\n",
        "    fig, ax = plt.subplots(figsize=(int(alignment_graph_width/100), int(alignment_graph_height/100)))\n",
        "    im = ax.imshow(alignment, cmap='inferno', aspect='auto', origin='lower',\n",
        "                   interpolation='none')\n",
        "    ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
        "    fig.colorbar(im, ax=ax)\n",
        "    xlabel = 'Decoder timestep'\n",
        "    if info is not None:\n",
        "        xlabel += '\\n\\n' + info\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel('Encoder timestep')\n",
        "    plt.tight_layout()\n",
        "    fig.canvas.draw()\n",
        "    plt.show()\n",
        "\n",
        "def validate(model, criterion, valset, iteration, batch_size, n_gpus,\n",
        "             collate_fn, logger, distributed_run, rank, epoch, start_eposh, learning_rate):\n",
        "    \"\"\"Handles all the validation scoring and printing\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_sampler = DistributedSampler(valset) if distributed_run else None\n",
        "        val_loader = DataLoader(valset, sampler=val_sampler, num_workers=1,\n",
        "                                shuffle=False, batch_size=batch_size,\n",
        "                                pin_memory=False, collate_fn=collate_fn)\n",
        "\n",
        "        val_loss = 0.0\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            x, y = model.parse_batch(batch)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            if distributed_run:\n",
        "                reduced_val_loss = reduce_tensor(loss.data, n_gpus).item()\n",
        "            else:\n",
        "                reduced_val_loss = loss.item()\n",
        "            val_loss += reduced_val_loss\n",
        "        val_loss = val_loss / (i + 1)\n",
        "\n",
        "    model.train()\n",
        "    if rank == 0:\n",
        "        print(\"Epoch: {} Validation loss {}: {:9f}  Time: {:.1f}m LR: {:.6f}\".format(epoch, iteration, val_loss,(time.perf_counter()-start_eposh)/60, learning_rate))\n",
        "        logger.log_validation(val_loss, model, y, y_pred, iteration)\n",
        "        if hparams.show_alignments:\n",
        "            %matplotlib inline\n",
        "            _, mel_outputs, gate_outputs, alignments = y_pred\n",
        "            idx = random.randint(0, alignments.size(0) - 1)\n",
        "            plot_alignment(alignments[idx].data.cpu().numpy().T)\n",
        "\n",
        "def train(output_directory, log_directory, checkpoint_path, warm_start, n_gpus,\n",
        "          rank, group_name, hparams, log_directory2):\n",
        "    \"\"\"Training and validation logging results to tensorboard and stdout\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    output_directory (string): directory to save checkpoints\n",
        "    log_directory (string) directory to save tensorboard logs\n",
        "    checkpoint_path(string): checkpoint path\n",
        "    n_gpus (int): number of gpus\n",
        "    rank (int): rank of current gpu\n",
        "    hparams (object): comma separated list of \"name=value\" pairs.\n",
        "    \"\"\"\n",
        "    logging.debug(\"----------------\")\n",
        "    logging.debug(\"start trainning\")\n",
        "    logging.debug(\"checkpoint_path = %s\", checkpoint_path)\n",
        "    if hparams.distributed_run:\n",
        "        init_distributed(hparams, n_gpus, rank, group_name)\n",
        "\n",
        "    torch.manual_seed(hparams.seed)\n",
        "    torch.cuda.manual_seed(hparams.seed)\n",
        "\n",
        "    logging.debug('调用load_model函数')\n",
        "    model = load_model(hparams) # model是model.py中的Tacotron2类\n",
        "\n",
        "    learning_rate = hparams.learning_rate\n",
        "    logging.debug('learning_rate = %d',learning_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
        "                                 weight_decay=hparams.weight_decay)\n",
        "\n",
        "    # if hparams.fp16_run: # 未开启\n",
        "    #   from apex import amp\n",
        "    #   model, optimizer = amp.initialize(\n",
        "    #     model, optimizer, opt_level='O2')\n",
        "\n",
        "    # if hparams.distributed_run: # 未开启\n",
        "    #     model = apply_gradient_allreduce(model)\n",
        "\n",
        "    criterion = Tacotron2Loss() # 在loss_function.py中的一个类\n",
        "    # 也是继承了torch.nn\n",
        "    # 定义了一个forward函数，之后用到再看\n",
        " \n",
        "    logger = prepare_directories_and_logger(output_directory, log_directory, rank) # 调用了上文中定义的函数，准备输出路径和输出调试信息的工具，不重要\n",
        "\n",
        "    train_loader, valset, collate_fn = prepare_dataloaders(hparams)\n",
        "\n",
        "    # Load checkpoint if one exists\n",
        "    iteration = 0\n",
        "    epoch_offset = 0\n",
        "    logging.debug('尝试读取checkpoint')\n",
        "    logging.debug('checkpoint_path = %s', checkpoint_path)\n",
        "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
        "        logging.debug(\"读取了checkpoint\")\n",
        "        if warm_start:\n",
        "            logging.debug(\"启动warm_start\")\n",
        "            model = warm_start_model(\n",
        "                checkpoint_path, model, hparams.ignore_layers)\n",
        "        else:\n",
        "            logging.debug(\"没有启动warm_start\")\n",
        "            model, optimizer, _learning_rate, iteration = load_checkpoint( # 调用上文定义的load_checkpoint函数\n",
        "                checkpoint_path, model, optimizer)\n",
        "            if hparams.use_saved_learning_rate:\n",
        "                logging.debug(\"选择use_saved_learning_rate\")\n",
        "                learning_rate = _learning_rate\n",
        "            iteration += 1  # 从上次训练结束时的iteration + 1开始\n",
        "            epoch_offset = max(0, int(iteration / len(train_loader))) # len(train_loader) = batches的数量 ； 好理解，iteration是训练一个bath_size，epoch是所有数据训练一遍\n",
        "    else:\n",
        "      # 如果不在checkpoint_path指定预训练模型的话，程序就会走这里，调用默认的预训练模型tacotron2_statedict.pt，也默认启动warm_start\n",
        "      os.path.isfile(\"tacotron2_statedict.pt\")\n",
        "      model = warm_start_model(\"tacotron2_statedict.pt\", model, hparams.ignore_layers)\n",
        "      # download LJSpeech pretrained model if no checkpoint already exists\n",
        "    \n",
        "    start_eposh = time.perf_counter() # 这个函数大概可以看作一个高精度的计时器\n",
        "    learning_rate = 0.0\n",
        "    model.train() # 将当前模块设置成训练模式.\n",
        "    is_overflow = False\n",
        "    # ================ MAIN TRAINNIG LOOP! ===================\n",
        "    for epoch in tqdm(range(epoch_offset, hparams.epochs)): # hparams.epochs就是训练的epoch次数，就是接着上次训练剩余的次数继续。\n",
        "        # tqdm是展示进度条的库\n",
        "        # 上面这个tqdm(range)也比较好理解，比如说是tqdm(range(4,50))，那训练到epoch = 27时这个进度条就走了一半了\n",
        "        print(\"\\nStarting Epoch: {} Iteration: {}\".format(epoch, iteration))\n",
        "        start_eposh = time.perf_counter() # eposh is russian, not a typo\n",
        "\n",
        "        # 这个enumerate(train_loader)比较重要，返回的i是batch的序号，batch里包含两个信息，一个是训练数据，一个是label。\n",
        "        for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)): \n",
        "            start = time.perf_counter() # 初始化计时器为0\n",
        "            # 反正是在调整学习率\n",
        "            if iteration < hparams.decay_start: learning_rate = hparams.A_ # 这个decay_start是什么意思？？一开始的hparams.A设的很小，一开始进去的数据热热身？\n",
        "            else: iteration_adjusted = iteration - hparams.decay_start; learning_rate = (hparams.A_*(e**(-iteration_adjusted/hparams.B_))) + hparams.C_\n",
        "\n",
        "\n",
        "            learning_rate = max(hparams.min_learning_rate, learning_rate) # output the largest number\n",
        "            logging.debug(\"epoch = %d\", epoch)\n",
        "            logging.debug(\"batch_num = %d\", i)\n",
        "            logging.debug(\"learning_rate = %f\", learning_rate)\n",
        "\n",
        "            # 这步不懂\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = learning_rate\n",
        "\n",
        "\n",
        "            model.zero_grad() # 将模型的所有参数的梯度清零.\n",
        "            x, y = model.parse_batch(batch)\n",
        "            y_pred = model(x)\n",
        "            \n",
        "            print(\"断点1\")\n",
        "            logging.debug(\"断点1\")\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "            if hparams.distributed_run: # 不启用\n",
        "                reduced_loss = reduce_tensor(loss.data, n_gpus).item()\n",
        "            else:\n",
        "                reduced_loss = loss.item()\n",
        "            if hparams.fp16_run: # 不启用\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                #走这里\n",
        "                loss.backward()\n",
        "\n",
        "            if hparams.fp16_run:\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                    amp.master_params(optimizer), hparams.grad_clip_thresh)\n",
        "                is_overflow = math.isnan(grad_norm)\n",
        "            else:\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                    model.parameters(), hparams.grad_clip_thresh)\n",
        "\n",
        "            optimizer.step()\n",
        "            print(\"断点2\")\n",
        "            logging.debug(\"断点2\")\n",
        "            if not is_overflow and rank == 0:\n",
        "                duration = time.perf_counter() - start\n",
        "                logger.log_training(\n",
        "                    reduced_loss, grad_norm, learning_rate, duration, iteration)\n",
        "                #print(\"Batch {} loss {:.6f} Grad Norm {:.6f} Time {:.6f}\".format(iteration, reduced_loss, grad_norm, duration), end='\\r', flush=True)\n",
        "\n",
        "            iteration += 1\n",
        "        print(\"断点3\")\n",
        "        logging.debug(\"断点3\")\n",
        "        validate(model, criterion, valset, iteration,\n",
        "                 hparams.batch_size, n_gpus, collate_fn, logger,\n",
        "                 hparams.distributed_run, rank, epoch, start_eposh, learning_rate)\n",
        "        save_checkpoint(model, optimizer, learning_rate, iteration, checkpoint_path)\n",
        "        if log_directory2 != None:\n",
        "            copy_tree(log_directory, log_directory2)\n",
        "def check_dataset(hparams):\n",
        "    from utils import load_wav_to_torch, load_filepaths_and_text\n",
        "    import os\n",
        "    import numpy as np\n",
        "    def check_arr(filelist_arr):\n",
        "        for i, file in enumerate(filelist_arr):\n",
        "            if len(file) > 2:\n",
        "                print(\"|\".join(file), \"\\nhas multiple '|', this may not be an error.\")\n",
        "            if hparams.load_mel_from_disk and '.wav' in file[0]:\n",
        "                print(\"[WARNING]\", file[0], \" in filelist while expecting .npy .\")\n",
        "            else:\n",
        "                if not hparams.load_mel_from_disk and '.npy' in file[0]:\n",
        "                    print(\"[WARNING]\", file[0], \" in filelist while expecting .wav .\")\n",
        "            if (not os.path.exists(file[0])):\n",
        "                print(\"|\".join(file), \"\\n[WARNING] does not exist.\")\n",
        "            if len(file[1]) < 3:\n",
        "                print(\"|\".join(file), \"\\n[info] has no/very little text.\")\n",
        "            if not ((file[1].strip())[-1] in r\"!?,.;:\"):\n",
        "                print(\"|\".join(file), \"\\n[info] has no ending punctuation.\")\n",
        "            mel_length = 1\n",
        "            if hparams.load_mel_from_disk and '.npy' in file[0]:\n",
        "                melspec = torch.from_numpy(np.load(file[0], allow_pickle=True))\n",
        "                mel_length = melspec.shape[1]\n",
        "            if mel_length == 0:\n",
        "                print(\"|\".join(file), \"\\n[WARNING] has 0 duration.\")\n",
        "    print(\"Checking Training Files\")\n",
        "    audiopaths_and_text = load_filepaths_and_text(hparams.training_files) # get split lines from training_files text file.\n",
        "    check_arr(audiopaths_and_text)\n",
        "    print(\"Checking Validation Files\")\n",
        "    audiopaths_and_text = load_filepaths_and_text(hparams.validation_files) # get split lines from validation_files text file.\n",
        "    check_arr(audiopaths_and_text)\n",
        "    print(\"Finished Checking\")\n",
        "\n",
        "warm_start=False #sorry about that\n",
        "n_gpus=1\n",
        "rank=0\n",
        "group_name=None\n",
        "\n",
        "# ---- 这是定义的默认参数，可以不用管 ----\n",
        "hparams = create_hparams()\n",
        "model_filename = 'current_model'\n",
        "hparams.training_files = \"filelists/clipper_train_filelist.txt\"\n",
        "hparams.validation_files = \"filelists/clipper_val_filelist.txt\"\n",
        "#hparams.use_mmi=True,          # not used in this notebook\n",
        "#hparams.use_gaf=True,          # not used in this notebook\n",
        "#hparams.max_gaf=0.5,           # not used in this notebook\n",
        "#hparams.drop_frame_rate = 0.2  # not used in this notebook\n",
        "hparams.p_attention_dropout=0.1\n",
        "hparams.p_decoder_dropout=0.1\n",
        "hparams.decay_start = 15000\n",
        "hparams.A_ = 5e-4\n",
        "hparams.B_ = 8000\n",
        "hparams.C_ = 0\n",
        "hparams.min_learning_rate = 1e-5\n",
        "generate_mels = True\n",
        "hparams.show_alignments = True\n",
        "alignment_graph_height = 600\n",
        "alignment_graph_width = 1000\n",
        "hparams.batch_size = 32\n",
        "hparams.load_mel_from_disk = True\n",
        "hparams.ignore_layers = []\n",
        "hparams.epochs = 10000\n",
        "\n",
        "torch.backends.cudnn.enabled = hparams.cudnn_enabled\n",
        "torch.backends.cudnn.benchmark = hparams.cudnn_benchmark\n",
        "output_directory = '/content/drive/MyDrive/colab/outdir' # Location to save Checkpoints\n",
        "log_directory = '/content/tacotron2/logs' # Location to save Log files locally\n",
        "log_directory2 = '/content/drive/MyDrive/colab/logs' # Location to copy log files (done at the end of each epoch to cut down on I/O)e\n",
        "checkpoint_path = output_directory+(r'/')+model_filename\n"
      ]
    }
  ]
}